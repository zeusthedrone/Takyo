{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ce590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "full_file_path = os.path.join(os.getcwd(),\"rlog1.csv\")\n",
    "df = pd.read_csv(full_file_path, encoding=\"ISO-8859-1\", na_values=['NA','?'])\n",
    "\n",
    "pd.set_option('display.max_columns', 11) \n",
    "pd.set_option('display.max_rows', 5)\n",
    "print(df.shape)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c291ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatString(instr, cnt, delim):\n",
    "    sp = \"                                    \"\n",
    "    if (cnt > 32):\n",
    "        cnt = 32\n",
    "    s = str(instr) + sp\n",
    "    o = s[0:cnt] + str(delim)\n",
    "    return o    \n",
    "def rformatString(instr, cnt, delim):\n",
    "    sp = \"                                    \"\n",
    "    if (cnt > 32):\n",
    "        cnt = 32\n",
    "    s = sp + str(instr) \n",
    "    o = s[-cnt:] + str(delim)\n",
    "    return o    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe26ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Missing Values\n",
    "def strToInt(str):\n",
    "    i = 0\n",
    "    try: \n",
    "        i = int(str)\n",
    "    except ValueError:\n",
    "        i = 0\n",
    "    return i\n",
    "\n",
    "def myfunc(x):\n",
    "    return strToInt(x.sum())\n",
    "\n",
    "totrecs = strToInt(df.shape[0])\n",
    "print(\"Missing Values\")\n",
    "print(\"     Total records: \", totrecs)\n",
    "\n",
    "print(rformatString(\"Cnt\",4,\"\"),formatString(\"Field Name\", 24,\" \"), rformatString(\"Missing\",7,\" \") ,rformatString(\"Pct Missing\",12, \"\"))\n",
    "cnt = 1\n",
    "for c in df.columns:\n",
    "    sn = df[c].isna().agg(myfunc)\n",
    "    p = 0\n",
    "    if sn != 0:\n",
    "        p = (sn / totrecs) * 100\n",
    "        p = format(p,\".2f\")\n",
    "    print(rformatString(cnt, 4,\"\"),formatString(c, 24, \" \"), rformatString(sn, 7, \" \") ,rformatString(p, 10, \" %\"))\n",
    "    cnt +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbdc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (total column missing values == total records) drop column \n",
    "print(\"Count Unique Indexes and Drop missing columns: \", df.shape)\n",
    "droplist = []\n",
    "#df.columns = [x.lower() for x in df.columns]\n",
    "for c in df.columns:\n",
    "    n = df[c].isna().sum()\n",
    "    if n == df.shape[0]:\n",
    "        droplist.append(c)\n",
    "print(\"Dropped Null Columns \",droplist)\n",
    "print(rformatString(\"Cnt\", 4,\"\"),formatString(\"Index\", 24,\"\") ,rformatString(\"Unique\", 8,\"\"),rformatString(\"isNull\", 8,\" \"), formatString(\"Class\", 24,\"\"))\n",
    "df.drop(labels=droplist, axis=1, inplace=True)\n",
    "cnt = 0\n",
    "for c in df.columns:\n",
    "    s = df[c].nunique()\n",
    "    n = df[c].isna().sum()\n",
    "    if n == df.shape[0]:\n",
    "        droplist.append(c)\n",
    "    print(rformatString(cnt, 4,\"\"),formatString(c, 24,\" \") ,rformatString(s, 7,\" \"),rformatString(n, 7,\" \"), formatString(type(c), 24,\"\"))\n",
    "    cnt +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b15081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filtered column indexes to lower: \")\n",
    "df.columns = [x.lower() for x in df.columns]\n",
    "for c in df.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0993ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Categorical data input \n",
    "# This data needs some explanation\n",
    "#   000 no sensors hit\n",
    "#   001 sensor hit on the right\n",
    "#   100 sensor hit on the left\n",
    "#   010 sensor hit in the middle\n",
    "#   110 sensor hit on left and middle \n",
    "#   011 sensor hit on right and middle\n",
    "#   101 sensor hit on left and right\n",
    "#   111 all sensors hit\n",
    "#   TOF same as CLIFF this sensor detects if the ground is present \n",
    "#         it is an edge detection to prevent robot from going down stairs\n",
    "#   CTG Clear To Go this means the robot has not hit a sensor\n",
    "#         for quite some time, this causes the robot to randomly turn\n",
    "#        \n",
    "scolumn = \"org\"                 # org - original hit\n",
    "nunique = df[scolumn].nunique()\n",
    "vcounts = pd.value_counts(df[scolumn])\n",
    "print(\"Unique \" + scolumn + \" : \", nunique)\n",
    "print(\"Code  Count\")\n",
    "pd.set_option('display.max_rows', 25)\n",
    "print(vcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7826eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# when robot starts averages are 0 zero\n",
    "# fill them with the mean value\n",
    "lmean = df['lftavg'].mean()\n",
    "rmean = df['rhtavg'].mean()\n",
    "df['lftavg'] = df['lftavg'].replace(0, lmean)\n",
    "df['rhtavg'] = df['rhtavg'].replace(0, rmean)\n",
    "print(lmean,rmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies for Categorical input original hit - org\n",
    "dummies = pd.get_dummies(df['org'],prefix=\"in\")\n",
    "pd.set_option('display.max_columns', 9)\n",
    "print(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve original dataframe\n",
    "df2 = pd.concat([df,dummies],axis=1)  # concat dummies \n",
    "df2.drop('org', axis=1, inplace=True) # original hit\n",
    "# drop dturn 'decision turn' this is a turn delay time \n",
    "#   it a random number between range(300-1000)\n",
    "#   computed after turn type\n",
    "df2.drop('dturn',axis=1,inplace=True) \n",
    "print(list(df2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d554d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "df2['compss'] = zscore(df2['compss'])   # compass heading in degrees 0-360\n",
    "df2['pitch'] = zscore(df2['pitch'])     # pitch \n",
    "df2['roll'] = zscore(df2['roll'])       # roll\n",
    "df2['cliff'] = zscore(df2['cliff'])     # edge detector alerts when ground is not sensed\n",
    "df2['lft'] = zscore(df2['lft'])         # infrared sensor left\n",
    "df2['ctr'] = zscore(df2['ctr'])         # ultrasonic sensor center\n",
    "df2['rht'] = zscore(df2['rht'])         # infrared sensor right\n",
    "df2['lastlft'] = zscore(df2['lastlft']) # time stamp of last hit\n",
    "df2['lastrht'] = zscore(df2['lastrht']) # time stamp of last hit\n",
    "df2['lftavg'] = zscore(df2['lftavg'])   # average of the last 20 hits\n",
    "df2['rhtavg'] = zscore(df2['rhtavg'])   # average of the last 20 hits\n",
    "\n",
    "# ddir or 'decision direction' is what we are trying to predict\n",
    "#          also called turntype\n",
    "x_columns = df2.columns.drop('ddir') \n",
    "x = df2[x_columns].values\n",
    "print(x_columns)\n",
    "\n",
    "# turntype or 'decision direction' is what we are trying to Classify\n",
    "dummies = pd.get_dummies(df2['ddir']) \n",
    "turntype = dummies.columns\n",
    "print(turntype)\n",
    "y = dummies.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a9e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, input_dim=x.shape[1], activation='relu',\n",
    "                kernel_initializer='random_normal'))\n",
    "model.add(tf.keras.layers.Dense(50,activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(tf.keras.layers.Dense(25,activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(tf.keras.layers.Dense(y.shape[1],activation='softmax',\n",
    "                kernel_initializer='random_normal'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                metrics =['accuracy'])\n",
    "monitor = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, \n",
    "                        verbose=1, mode='auto', restore_best_weights=True)\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "          callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1) \n",
    "# raw probabilities to chosen class (highest probability)\n",
    "from sklearn import metrics\n",
    "\n",
    "y_compare = np.argmax(y_test,axis=1) \n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63982fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Don't display numpy in scientific notation\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Generate predictions\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(\"Numpy array of predictions\")\n",
    "display(pred[0:5])\n",
    "\n",
    "print(\"As percent probability\")\n",
    "print(pred[0]*100)\n",
    "\n",
    "score = metrics.log_loss(y_test, pred)\n",
    "print(\"Log loss score: {}\".format(score))\n",
    "\n",
    "# raw probabilities to chosen class (highest probability)\n",
    "pred = np.argmax(pred,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd527cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure, show\n",
    "from numpy import arange, sin, pi\n",
    "\n",
    "#t = arange(1e-5, 5.0, 0.00001)\n",
    "#t = arange(1.0, 5.0, 0.00001) # computer scientists\n",
    "t = arange(0.0, 1.0, 0.00001)  # data     scientists\n",
    "\n",
    "fig = figure(1,figsize=(12, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(t, np.log(t))\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim((-8, 1.5))\n",
    "ax1.set_xlim((-0.1, 2))\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('log(x)')\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = metrics.confusion_matrix(y_compare, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "print(cm_normalized.shape)\n",
    "#plt.figure()\n",
    "##plt.plot(cm_normalized)#,products)\n",
    "#plt.show()\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=cm_normalized)\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec7d94e9204ec760bc77d3286f185d123c772dee90baf763f2e61f9c34d211cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
